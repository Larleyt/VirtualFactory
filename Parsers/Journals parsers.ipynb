{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(root_dir=None, prefix=None):\n",
    "    file_paths = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for name in files:\n",
    "            if name.decode(\"utf-8\").lower().startswith(prefix):\n",
    "                file_paths.append(os.path.join(root, name))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_journal(fpath, output_path):\n",
    "    xls = pd.ExcelFile(fpath)\n",
    "\n",
    "    # Parse Status sheet\n",
    "    df = xls.parse(\n",
    "        sheetname=0, \n",
    "        header=0,\n",
    "        index_col=0,\n",
    "        parse_cols=\"B:E\"\n",
    "    )\n",
    "    \n",
    "    df.to_csv(\n",
    "        os.path.join(output_path, 'СТАТУС.csv'), \n",
    "        encoding=\"utf-8\", \n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    \n",
    "    # Parse Machinetools sheets \n",
    "    for sheet_idx in range(1, 13):\n",
    "        df = xls.parse(\n",
    "            sheetname=sheet_idx, \n",
    "            header=1,\n",
    "            parse_cols=\"B:N\",\n",
    "            skiprows=[2]\n",
    "        )\n",
    "        \n",
    "        # Cпособ найти индекс строки, где начинается ненужная часть таблицы\n",
    "        # -4 нужно для багованных листов, где 00:00 проставлено до конца листа :(\n",
    "        try:\n",
    "            max_idx = df.loc[df.isnull().all(axis=1)].index[0]\n",
    "        except IndexError:\n",
    "            max_idx = -4\n",
    "        \n",
    "        filename = xls.sheet_names[sheet_idx].encode(\"utf-8\") + \"_станок.csv\"\n",
    "        df[:max_idx].to_csv(\n",
    "            os.path.join(output_path, filename), \n",
    "            encoding=\"utf-8\",\n",
    "            sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "def parse_plan(fpath, output_path):\n",
    "    xls = pd.ExcelFile(fpath)\n",
    "    xls.sheet_names\n",
    "\n",
    "    df = xls.parse(\n",
    "        sheetname=0,\n",
    "        header=0,\n",
    "        index_col=None\n",
    "    ).dropna(how='all', axis=1).dropna(how='all')\n",
    "    \n",
    "    # ~ old\n",
    "    # find out num of header rows\n",
    "    # headers_num = 0\n",
    "    # for index, row in df.iterrows():\n",
    "    #     if not np.isnan(index):\n",
    "    #         break\n",
    "    #     headers_num += 1\n",
    "\n",
    "    # max_multiindex_row = df.loc[\n",
    "    #     df[u\"Наименование\"].str.contains(u\"Заказ\", case=False, na=False)\n",
    "    # ]\n",
    "    \n",
    "    headers_num = 3\n",
    "    df = df[df[u\"Наименование\"].notnull()].reset_index(drop=False)\n",
    "    # Create order_num column\n",
    "    # df.insert(0, column=u\"whatever\", value=np.nan)\n",
    "    df = df.reindex(method='ffill')\n",
    "    print \"DFFFFF\"\n",
    "    print df.head()\n",
    "    \n",
    "    xx = xls.parse(\n",
    "        sheetname=0,\n",
    "        header=None,\n",
    "        index_col=0\n",
    "    )[0:headers_num].dropna(how='all', axis=1).dropna(how='all')\n",
    "    \n",
    "    # xx.insert(0, column=u\"whatever\", value=u\"Заказ\")\n",
    "    \n",
    "    xx.iloc[0,0] = u\"Номер детали\"\n",
    "    # Fill down\n",
    "    xx.fillna(method='ffill', axis=0, inplace=True)\n",
    "    # Fill across\n",
    "    # xx = xx.fillna(method='ffill', axis=1)\n",
    "    \n",
    "    print \"THE XXXXXXXXXXXXX\"\n",
    "    print xx.head()\n",
    "    xx.to_csv(\n",
    "        os.path.join(output_path, 'multi_index.csv'),\n",
    "        header=False,\n",
    "        index=False,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    mxx = pd.read_csv(\n",
    "        os.path.join(output_path, 'multi_index.csv'), \n",
    "        header=[0,1,2],\n",
    "        skipinitialspace=True,\n",
    "        tupleize_cols=True,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print len(mxx.columns)\n",
    "    df.columns = pd.MultiIndex.from_tuples(mxx.columns)\n",
    "    \n",
    "    df.to_csv(\n",
    "        os.path.join(output_path, \"parsed_План.csv\"), \n",
    "        encoding=\"utf-8\",\n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    return df.head()\n",
    "    \n",
    "    # dff = xls.parse(\n",
    "    #     sheetname=0,\n",
    "    #     header=[0,1,2],\n",
    "    #     index_col=None\n",
    "    # )\n",
    "    # dff = dff.reindex(method='ffill')\n",
    "    # dff.fillna(method='ffill', axis=0, inplace=True)\n",
    "    # dff = dff.fillna(method='ffill', axis=1)\n",
    "    # ~\n",
    "\n",
    "    # # Headers as rows for now\n",
    "    # df = xls.parse(sheetname=0, header=None, index_col=None)\n",
    "    # \n",
    "    # # Create order_num column\n",
    "    # #df.insert(0, column=u\"whatever\", value=np.nan)\n",
    "    # \n",
    "    # headers = df.iloc[:headers_num]\n",
    "    # \n",
    "    # # Fill down\n",
    "    # headers = headers.fillna(method='ffill')\n",
    "    # # fill few column indicies (fucked up indexing)\n",
    "    # headers.iloc[0,0] = u\"Номер заказа\"\n",
    "    # headers.iloc[0,1] = u\"Номер детали\"\n",
    "    # \n",
    "    # # Fill across (carefully)\n",
    "    # headers_not_to_fill = headers.iloc[:,:5]\n",
    "    # \n",
    "    # headers_to_fill = headers.iloc[:,5:]\n",
    "    # headers = pd.concat([\n",
    "    #     headers_not_to_fill,\n",
    "    #     headers_to_fill.fillna(method='ffill', axis=1)\n",
    "    # ], axis=1)\n",
    "    # \n",
    "    # df = df.iloc[headers_num:]\n",
    "    # df = df.reset_index(drop=True)\n",
    "\n",
    "    # Create multiindex column names\n",
    "    # df.columns = pd.MultiIndex.from_arrays(mxx.values.tolist())\n",
    "    # dup_first_index_dates = df.columns\n",
    "    # print df.head()\n",
    "    # blah = df[u\"Наименование\"] #.ix[df[u\"Наименование\"].notnull()].index.tolist()\n",
    "    # print blah\n",
    "    # max_multiindex_row = df.loc[\n",
    "    #     df[u\"Наименование\"].str.contains(u\"Заказ\", case=False, na=False)\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_journals(fpaths, output_path):\n",
    "    for xls_path in fpaths:\n",
    "        print \"Processing status sheets: \" + str(xls_path)\n",
    "        xls = pd.ExcelFile(xls_path)\n",
    "    \n",
    "        # Parse Status sheet\n",
    "        df_status = xls.parse(\n",
    "            sheetname=0, \n",
    "            header=0,\n",
    "            index_col=0,\n",
    "            parse_cols=\"B:E\"\n",
    "        )\n",
    "        \n",
    "        df_status.to_csv(\n",
    "            os.path.join(output_path, 'СТАТУС.csv'), \n",
    "            encoding=\"utf-8\", \n",
    "            sep=\"\\t\"\n",
    "        )\n",
    "    \n",
    "    # Parse Machinetools sheets\n",
    "    machinetool_names = []\n",
    "    machinetool_frames = []\n",
    "    for sheet_idx in range(1, 13):\n",
    "        print \"Processing machinetools sheet for each journal: \" + str(sheet_idx)\n",
    "        year_frames = []\n",
    "        \n",
    "        for xls_path in fpaths:\n",
    "            xls = pd.ExcelFile(xls_path)\n",
    "\n",
    "            df = xls.parse(\n",
    "                sheetname=sheet_idx,\n",
    "                header=1,\n",
    "                parse_cols=\"B:N\",\n",
    "                skiprows=[2]\n",
    "            ).dropna(how='all', axis=1).dropna(how='all')\n",
    "            \n",
    "            if any(df[u\"Время старт (чч:мм)\"] == u\"Статус\"):\n",
    "                df = df[:-4]\n",
    "            year_frames.append(df)\n",
    "            \n",
    "        machinetool_names.append(xls.sheet_names[sheet_idx])\n",
    "        machinetool_df = pd.concat(year_frames, ignore_index=True)\n",
    "        machinetool_frames.append(machinetool_df)\n",
    "        # filename = xls.sheet_names[sheet_idx].encode(\"utf-8\") + \"_станок.csv\"\n",
    "    \n",
    "    result = pd.concat(\n",
    "        machinetool_frames, \n",
    "        keys=machinetool_names,\n",
    "        names=[u\"Станок\", u\"Index\"]\n",
    "    )\n",
    "    result.to_csv(\n",
    "        os.path.join(output_path, u\"Журнал станков за 3 месяца.csv\"),\n",
    "        encoding=\"utf-8\",\n",
    "        sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFFFFF\n  index                                       Наименование  \\\n0   NaN  Заказ № 11463 от 28.12.2011  500шт. Март 500шт...   \n1     1                             ЦДКТ.731111.001 Корпус   \n2   NaN  Заказ № 11461 от 27.11.2011  срок поставки 15....   \n3     1                             ЦДКТ.731123.005 Корпус   \n4     2                             ЦДКТ.754142.040 Крышка   \n\n            срок сдачи кол-во заказ изготовлено           Unnamed: 4  \\\n0                  NaN          NaN         NaN                  NaN   \n1                  NaN         1000         NaN                  NaN   \n2                  NaN          NaN         NaN                  NaN   \n3  2012-02-24 00:00:00           13          14  2012-02-10 00:00:00   \n4  2012-02-15 00:00:00           13          20  2012-02-08 00:00:00   \n\n  Unnamed: 5 Unnamed: 6   Unnamed: 7  \\\n0        NaN        NaN          NaN   \n1        NaN        NaN          NaN   \n2        NaN        NaN          NaN   \n3        NaN        NaN  Шкляев И.Н.   \n4        NaN        NaN  Шкляев И.Н.   \n\n                                       заготовка     ...     Unnamed: 41  \\\n0                                            NaN     ...             NaN   \n1                             Д16      170x90#45     ...             NaN   \n2                                            NaN     ...             NaN   \n3                  Пруток ДКРНТ  D25xL80  ЛС59-1     ...             NaN   \n4   ДПРНМ 0,6  205x305#0,6* зам-ль ДПРНМ 0,5 Л63     ...             NaN   \n\n  Отгружено-Приход Unnamed: 43 Unnamed: 44 Unnamed: 45 Unnamed: 46  \\\n0              NaN         NaN         NaN         NaN         NaN   \n1              NaN         NaN         NaN         NaN         NaN   \n2              NaN         NaN         NaN         NaN         NaN   \n3              NaN         NaN         NaN         NaN         NaN   \n4              NaN         NaN         NaN         NaN         NaN   \n\n  Unnamed: 47 Unnamed: 48 Unnamed: 49 Unnamed: 50  \n0         NaN         NaN         NaN         NaN  \n1         NaN         NaN         NaN         NaN  \n2         NaN         NaN         NaN         NaN  \n3         NaN         NaN         NaN         NaN  \n4         NaN         NaN         NaN         NaN  \n\n[5 rows x 52 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE XXXXXXXXXXXXX\n               1           2             3            4     5        6   \\\n0                                                                         \nNaN  Номер детали  срок сдачи  кол-во заказ  изготовлено   NaN      NaN   \nNaN  Номер детали  срок сдачи  кол-во заказ       Станок   NaN            \nNaN  Номер детали  срок сдачи  кол-во заказ       кол-во  дата  подг.вр   \n\n          7              8              9              10   ...          42  \\\n0                                                           ...               \nNaN      NaN            NaN      заготовка            NaN   ...         NaN   \nNaN      NaN            NaN  размеры марка  срок поставки   ...       Цех 1   \nNaN  маш.вр.  ответственный  размеры марка  срок поставки   ...    В. Шоссе   \n\n                   43      44      45      46      47      48      49      50  \\\n0                                                                               \nNaN  Отгружено-Приход     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \nNaN          Покрытие     NaN  Аксион     NaN  Спектр     NaN  Прочие     NaN   \nNaN            Расход  Приход  Расход  Приход  Расход  Приход  Расход  Приход   \n\n         51  \n0            \nNaN     NaN  \nNaN     СТМ  \nNaN  Расход  \n\n[3 rows x 51 columns]\n51\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 52 elements, new values have 51 elements",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-88823aae9b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# parse_journals(journal_file_paths, OUTPUT_JOURNALS_PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mparse_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PLANS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c87a4b0fcbf1>\u001b[0m in \u001b[0;36mparse_plan\u001b[0;34m(fpath, output_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     df.to_csv(\n",
      "\u001b[0;32m/home/larleyt/.virtualenvs/ML_venv/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas/lib.c:44872)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/larleyt/.virtualenvs/ML_venv/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/larleyt/.virtualenvs/ML_venv/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2800\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2801\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2802\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 52 elements, new values have 51 elements"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "ROOT_DIR = r\"/home/larleyt/fl/ML/VirtualFactory/data collection\"\n",
    "OUTPUT_JOURNALS_PATH = ROOT_DIR + r\"/CSVs/Journals\"\n",
    "OUTPUT_PLANS_PATH = ROOT_DIR + r\"/CSVs/Plans\"\n",
    "\n",
    "journal_file_paths = find_files(ROOT_DIR, u\"новый\")\n",
    "plan_file_paths = find_files(ROOT_DIR, u\"план 2012-16\")\n",
    "\n",
    "# parse_journals(journal_file_paths, OUTPUT_JOURNALS_PATH)\n",
    "parse_plan(plan_file_paths[0], OUTPUT_PLANS_PATH)\n",
    "\n",
    "\n",
    "# for xls_path in journal_file_paths:\n",
    "#     print \"Processing journals: \" + xls_path\n",
    "#     xls_named_dir = os.path.join(\n",
    "#         OUTPUT_JOURNALS_PATH, \n",
    "#         os.path.basename(xls_path).split(\".\")[0])\n",
    "#     print xls_path\n",
    "#     if not os.path.exists(xls_named_dir):\n",
    "#         os.mkdir(xls_named_dir)\n",
    "#     parse_journal(xls_path, xls_named_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}